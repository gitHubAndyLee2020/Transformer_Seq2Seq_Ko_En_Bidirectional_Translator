{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMpNCVFn8al1HszYNs2F1KP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gitHubAndyLee2020/Transformer_Seq2Seq_Ko_En_Bidirectional_Translator/blob/main/test_translation_module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "68GlpUmMF_OH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip kr_en_translation_ted_talk_dataset.zip"
      ],
      "metadata": {
        "id": "OMBJ8crHGf5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'portalocker>=2.0.0'"
      ],
      "metadata": {
        "id": "MO7t9gzrHJyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchdata\n",
        "!pip install -U spacy\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "!python3 -m spacy download ko_core_news_sm"
      ],
      "metadata": {
        "id": "irIiS2kYHMKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FILE_PATH = 'multitarget-ted/en-ko/raw/'"
      ],
      "metadata": {
        "id": "KY0i0JtYKBRm"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "def load_file(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "    return [line.strip() for line in lines]\n",
        "\n",
        "def evaluate_bleu(model_translated_file, actual_translated_file, ln):\n",
        "    # Get tokenizer\n",
        "    if ln == 'en':\n",
        "        tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "    elif ln == 'ko':\n",
        "        tokenizer = get_tokenizer('spacy', language='ko_core_news_sm')\n",
        "    else:\n",
        "        print(\"Unsupported language\")\n",
        "        return\n",
        "\n",
        "    # Load files\n",
        "    model_translated_lines = load_file(model_translated_file)\n",
        "    actual_translated_lines = load_file(actual_translated_file)\n",
        "\n",
        "    # Check if lengths are equal\n",
        "    if len(model_translated_lines) != len(actual_translated_lines):\n",
        "        print(\"The number of lines in both files must be the same.\")\n",
        "        return\n",
        "\n",
        "    bleu_scores = []\n",
        "\n",
        "    for model_line, actual_line in zip(model_translated_lines, actual_translated_lines):\n",
        "        # Tokenize text\n",
        "        model_tokens = tokenizer(model_line.lower())\n",
        "        actual_tokens = tokenizer(actual_line.lower())\n",
        "\n",
        "        # Compute BLEU score\n",
        "        bleu_score = sentence_bleu([actual_tokens], model_tokens)\n",
        "        bleu_scores.append(bleu_score)\n",
        "\n",
        "    avg_bleu = sum(bleu_scores) / len(bleu_scores)\n",
        "    print(f'Average BLEU score: {avg_bleu * 100:.2f}')"
      ],
      "metadata": {
        "id": "C9ZYNZ1lF2uB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 1):\n",
        "  # Example usage\n",
        "  model_translated_file = f\"translated/translated_en_to_ko_epoch_{i}.txt\"\n",
        "  actual_translated_file = FILE_PATH + \"ted_test1_en-ko.raw.ko\"\n",
        "  ln = \"ko\"  # 'en' for English, 'ko' for Korean\n",
        "  print(\"Testing translated English-to-Korean text:\")\n",
        "  evaluate_bleu(model_translated_file, actual_translated_file, ln)\n",
        "\n",
        "  # Example usage\n",
        "  model_translated_file = f\"translated/translated_ko_to_en_epoch_{i}.txt\"\n",
        "  actual_translated_file = FILE_PATH + \"ted_test1_en-ko.raw.en\"\n",
        "  ln = \"en\"  # 'en' for English, 'ko' for Korean\n",
        "  print(\"Testing translated Korean-to-English text:\")\n",
        "  evaluate_bleu(model_translated_file, actual_translated_file, ln)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KO3yN75-KWj3",
        "outputId": "7e0e0d90-d723-47b1-f56d-78dc731c62df"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing translated English-to-Korean text:\n",
            "Average BLEU score: 0.09\n",
            "Testing translated Korean-to-English text:\n",
            "Average BLEU score: 0.37\n"
          ]
        }
      ]
    }
  ]
}